{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"id":"ZdhmJmk7Iv2c","executionInfo":{"status":"ok","timestamp":1701933088901,"user_tz":-540,"elapsed":84821,"user":{"displayName":"Aa AA","userId":"04662114637417837193"}}},"outputs":[],"source":["import numpy as np\n","import os\n","import cv2\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","\n","# 원본 이미지 데이터셋 경로 설정\n","v_original_folder = '/content/RL_fdr/violence'\n","nv_original_folder = '/content/RL_fdr/non_violence'\n","\n","# POSE 데이터셋 경로 설정\n","v_pose_folder = '/content/RL_pose/violence'\n","nv_pose_folder = '/content/RL_pose/non_violence'\n","\n","# 데이터셋 초기화\n","v_origin_images = []\n","nv_origin_images = []\n","v_pose_images = []\n","nv_pose_images = []\n","\n","# 원본 이미지 데이터셋 - 폭행 데이터\n","for folder_number in range(1, 1001):\n","    v_original_path = os.path.join(v_original_folder, str(folder_number))\n","\n","    # 폴더가 존재하지 않으면 넘어가기\n","    if not os.path.exists(v_original_path):\n","        continue\n","\n","    for v_img_file in os.listdir(v_original_path):\n","        # JPG 파일만 읽어오기\n","        if v_img_file.lower().endswith(\".jpg\"):\n","            v_origin_img_path = os.path.join(v_original_path, v_img_file)\n","\n","            try:\n","                v_origin_img_array = cv2.imread(v_origin_img_path)\n","                if v_origin_img_array is None or v_origin_img_array.size == 0:\n","                    print(f\"이미지를 읽을 수 없거나 비어 있습니다: {v_origin_img_path}\")\n","                    continue\n","\n","                v_origin_img_array_resized = cv2.resize(v_origin_img_array, (64, 64))  # 이미지 크기 리사이징\n","                v_origin_images.append(v_origin_img_array_resized)\n","            except Exception as e:\n","                print(f\"이미지 처리 중 오류 발생: {v_origin_img_path}\")\n","                print(f\"에러 메시지: {str(e)}\")\n","\n","# 원본 이미지 데이터셋 - 비폭행 데이터\n","for folder_number in range(1, 1001):\n","    nv_original_path = os.path.join(nv_original_folder, str(folder_number))\n","    for nv_img_file in os.listdir(nv_original_path):\n","        # JPG 파일만 읽어오기\n","        if nv_img_file.lower().endswith(\".jpg\"):\n","            nv_origin_img_path = os.path.join(nv_original_path, nv_img_file)\n","\n","            try:\n","                nv_origin_img_array = cv2.imread(nv_origin_img_path)\n","                if nv_origin_img_array is None or nv_origin_img_array.size == 0:\n","                    print(f\"이미지를 읽을 수 없거나 비어 있습니다: {nv_origin_img_path}\")\n","                    continue\n","\n","                nv_origin_img_array_resized = cv2.resize(nv_origin_img_array, (64, 64))  # 이미지 크기 리사이징\n","                nv_origin_images.append(nv_origin_img_array_resized)\n","            except Exception as e:\n","                print(f\"이미지 처리 중 오류 발생: {nv_origin_img_path}\")\n","                print(f\"에러 메시지: {str(e)}\")\n","\n","# POSE 데이터셋 - 폭행 데이터\n","for folder_number in range(1, 1001):\n","    v_pose_path = os.path.join(v_pose_folder, str(folder_number))\n","\n","    # 폴더가 존재하지 않으면 넘어가기\n","    if not os.path.exists(v_pose_path):\n","        continue\n","\n","    for v_img_file in os.listdir(v_pose_path):\n","        # JPG 파일만 읽어오기\n","        if v_img_file.lower().endswith(\".png\"):\n","            v_pose_img_path = os.path.join(v_pose_path, v_img_file)\n","\n","            try:\n","                v_pose_img_array = cv2.imread(v_pose_img_path)\n","                if v_pose_img_array is None or v_pose_img_array.size == 0:\n","                    print(f\"이미지를 읽을 수 없거나 비어 있습니다: {v_pose_img_path}\")\n","                    continue\n","\n","                v_pose_img_array_resized = cv2.resize(v_pose_img_array, (64, 64))  # 이미지 크기 리사이징\n","                v_pose_images.append(v_pose_img_array_resized)\n","            except Exception as e:\n","                print(f\"이미지 처리 중 오류 발생: {v_pose_img_path}\")\n","                print(f\"에러 메시지: {str(e)}\")\n","\n","# POSE 데이터셋 - 비폭행 데이터\n","for folder_number in range(1, 1001):\n","    nv_pose_path = os.path.join(nv_pose_folder, str(folder_number))\n","    for nv_img_file in os.listdir(nv_pose_path):\n","        # JPG 파일만 읽어오기\n","        if nv_img_file.lower().endswith(\".png\"):\n","            nv_pose_img_path = os.path.join(nv_pose_path, nv_img_file)\n","\n","            try:\n","                nv_pose_img_array = cv2.imread(nv_pose_img_path)\n","                if nv_pose_img_array is None or nv_pose_img_array.size == 0:\n","                    print(f\"이미지를 읽을 수 없거나 비어 있습니다: {nv_pose_img_path}\")\n","                    continue\n","\n","                nv_pose_img_array_resized = cv2.resize(nv_pose_img_array, (64, 64))  # 이미지 크기 리사이징\n","                nv_pose_images.append(nv_pose_img_array_resized)\n","            except Exception as e:\n","                print(f\"이미지 처리 중 오류 발생: {nv_pose_img_path}\")\n","                print(f\"에러 메시지: {str(e)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"twoIC78ogyZj"},"outputs":[],"source":["#이거 20분 넘게 걸림\n","\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import TimeDistributed, LSTM, Dense, Flatten, Input\n","from tensorflow.keras.models import Model\n","import numpy as np\n","import cv2\n","\n","# 이미지 특징 추출을 위한 VGG16 모델 불러오기\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n","\n","# 입력 레이어 생성\n","input_layer = Input(shape=(None, 32, 32, 3))\n","\n","# VGG16 모델에 LSTM 레이어 추가\n","x = TimeDistributed(base_model)(input_layer)\n","x = TimeDistributed(Flatten())(x)\n","x = LSTM(256, activation='tanh', return_sequences=False)(x)  # 변경된 부분\n","\n","# 모델 생성\n","model = Model(inputs=input_layer, outputs=x)\n","\n","# 특징 추출 함수 정의\n","def extract_features(images, sequence_length):\n","    features = []\n","    sequence_length = min(len(images), sequence_length)  # 이미지 리스트의 길이와 sequence_length 중 작은 값을 사용\n","    for i in range(sequence_length):\n","        # 이미지 리사이징\n","        resized_img = cv2.resize(images[i], (32, 32))\n","\n","        # 이미지 정규화\n","        normalized_img = resized_img / 255.0\n","\n","        # 이미지를 1차원 벡터로 변환\n","        img_vector = normalized_img.flatten()\n","\n","        features.append(img_vector)\n","\n","    # 3차원 배열로 변환 (시퀀스 길이, 64, 64, 3)\n","    return np.array(features).reshape(-1, 32, 32, 3)\n","\n","\n","sequence_length = 2\n","\n","# 원본 이미지와 포즈 이미지의 특징 추출 및 결합\n","combined_features_v = []\n","combined_features_nv = []\n","\n","for i, (v_origin_img, v_pose_img) in enumerate(zip(v_origin_images, v_pose_images)):\n","    print(f\"Processing v_origin_images and v_pose_images: {i+1}/{len(v_origin_images)}\")\n","\n","    # 원본 이미지의 특징 추출\n","    features_v_origin = model.predict(np.expand_dims(extract_features([v_origin_img], sequence_length), axis=0), verbose=0)\n","\n","    # 포즈 이미지의 특징 추출\n","    features_v_pose = model.predict(np.expand_dims(extract_features([v_pose_img], sequence_length), axis=0), verbose=0)\n","\n","    # 원본 이미지와 포즈 이미지의 특징을 결합\n","    combined_features_v.append(np.concatenate((features_v_origin, features_v_pose), axis=-1))\n","\n","for i, (nv_origin_img, nv_pose_img) in enumerate(zip(nv_origin_images, nv_pose_images)):\n","    print(f\"Processing nv_origin_images and nv_pose_images: {i+1}/{len(nv_origin_images)}\")\n","\n","    # 원본 이미지의 특징 추출\n","    features_nv_origin = model.predict(np.expand_dims(extract_features([nv_origin_img], sequence_length), axis=0), verbose=0)\n","\n","    # 포즈 이미지의 특징 추출\n","    features_nv_pose = model.predict(np.expand_dims(extract_features([nv_pose_img], sequence_length), axis=0), verbose=0)\n","\n","    # 원본 이미지와 포즈 이미지의 특징을 결합\n","    combined_features_nv.append(np.concatenate((features_nv_origin, features_nv_pose), axis=-1))\n"]},{"cell_type":"code","source":["import numpy as np\n","import os\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import TimeDistributed, LSTM, Dense, Flatten, Input\n","from tensorflow.keras.models import Model\n","from sklearn.metrics import accuracy_score\n","\n","# 클래스 레이블을 정의\n","labels_v = np.ones(len(combined_features_v))  # 예시: 클래스 1은 폭력 이미지\n","labels_nv = np.zeros(len(combined_features_nv))  # 예시: 클래스 0은 비폭력 이미지\n","\n","# 이미지와 레이블을 훈련 및 테스트 데이터셋으로 나눔\n","train_data, test_data, train_labels, test_labels = train_test_split(\n","    np.concatenate((combined_features_v, combined_features_nv)),\n","    np.concatenate((labels_v, labels_nv)),\n","    test_size=0.2,\n","    random_state=42,\n","    stratify=np.concatenate((labels_v, labels_nv))  # 클래스 레이블에 따라 계층화\n",")\n","\n","# 클래스 불균형 보정을 위해 데이터를 섞고 다시 분할\n","combined_images = np.concatenate((combined_features_v, combined_features_nv))\n","combined_labels = np.concatenate((labels_v, labels_nv))\n","combined_images, combined_labels = shuffle(combined_images, combined_labels, random_state=42)\n","\n","train_data, test_data, train_labels, test_labels = train_test_split(\n","    combined_images, combined_labels, test_size=0.2, random_state=42, stratify=combined_labels\n",")\n","\n","# 모델 정의 및 컴파일\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n","\n","input_layer = Input(shape=(None, 64, 64, 3))\n","x = TimeDistributed(base_model)(input_layer)\n","x = TimeDistributed(Flatten())(x)\n","x = LSTM(256, activation='relu', return_sequences=False)(x)\n","output_layer = Dense(1, activation='sigmoid')(x)\n","\n","model = Model(inputs=input_layer, outputs=output_layer)\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# 훈련 데이터셋 확인\n","print(\"Train data shape:\", train_data.shape)\n","print(\"Train labels:\", train_labels)\n","\n","# 테스트 데이터셋 확인\n","print(\"Test data shape:\", test_data.shape)\n","print(\"Test labels:\", test_labels)"],"metadata":{"id":"bHaUciuXQoPm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","train_data = np.squeeze(train_data, axis=1)\n","test_data = np.squeeze(test_data, axis=1)\n","\n","# 모델 구축\n","model = Sequential()\n","model.add(Dense(512, activation='relu', input_shape=(512,)))\n","model.add(Dropout(0.5))\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","\n","# 모델 컴파일\n","adam = Adam(learning_rate=0.0001)\n","model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# 조기 종료 설정\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n","\n","# 모델 훈련\n","history = model.fit(train_data, train_labels, epochs=30, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n","\n","# 훈련의 정확도와 손실 시각화\n","plt.figure(figsize=(12, 4))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['accuracy'], 'b-', label='accuracy')\n","plt.plot(history.history['val_accuracy'], 'r--', label='val_accuracy')\n","plt.xlabel('Epoch')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'], 'b-', label='loss')\n","plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n","plt.xlabel('Epoch')\n","plt.legend()\n","\n","plt.show()\n","\n","# 모델 평가\n","loss, accuracy = model.evaluate(test_data, test_labels)\n","print(f'테스트 손실: {loss}, 테스트 정확도: {accuracy}')"],"metadata":{"id":"vMZvFmYtG1FD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","# 모델 예측\n","preds = model.predict(test_data)\n","preds = np.round(preds)  # 이진 분류 문제의 경우 반올림으로 예측 클래스를 결정\n","\n","# 정밀도, 재현율, F1 스코어 계산\n","precision = precision_score(test_labels, preds)\n","recall = recall_score(test_labels, preds)\n","f1 = f1_score(test_labels, preds)\n","\n","print(f'Precision: {precision}, Recall: {recall}, F1 Score: {f1}')"],"metadata":{"id":"nCVMJgo89xP-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import roc_curve, roc_auc_score\n","import matplotlib.pyplot as plt\n","\n","# 모델에 대한 예측 수행\n","preds = model.predict(test_data).ravel()  # ravel()로 1차원 배열로 변경\n","\n","# ROC 커브 계산\n","fpr, tpr, thresholds = roc_curve(test_labels, preds)\n","\n","# AUC 계산\n","auc = roc_auc_score(test_labels, preds)\n","\n","# ROC 커브 그리기\n","plt.figure(figsize=(10, 8))\n","plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n","plt.plot([0, 1], [0, 1], color='navy', linestyle='--')  # 대각선\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate (FPR)')\n","plt.ylabel('True Positive Rate (TPR)')\n","plt.title('Receiver Operating Characteristic (ROC) curve')\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"metadata":{"id":"_U46WRQa9zGx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# VGG16 모델 불러오기\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n","\n","# 모델의 구조 출력\n","model.summary()"],"metadata":{"id":"AeFHOdQ6gmtu"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}